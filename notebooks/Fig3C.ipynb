{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ef17f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "netNMFMU imported\n",
      "netNMFGD imported\n"
     ]
    }
   ],
   "source": [
    "#5000 subset, 4000 genes, only global gene sets for SLALOM and netNMF\n",
    "from sklearn.decomposition import NMF\n",
    "from EM_SPADE import EMSPADE\n",
    "from pyspade_global import * \n",
    "from opt_einsum import contract\n",
    "import itertools\n",
    "from scipy.stats import spearmanr\n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import netNMFsc\n",
    "import joblib\n",
    "from util import *\n",
    "from schpf import scHPF, run_trials, run_trials_pool\n",
    "from schpf import load_model, save_model\n",
    "import numpy as np\n",
    "import pickle\n",
    "from ZIFA import ZIFA\n",
    "import slalom\n",
    "from slalom import plotFactors, plotRelevance, saveFA, dumpFA\n",
    "from util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42ae70b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask(input_lst, G_input, D):\n",
    "    input_mask = np.zeros((G_input, D))\n",
    "    for i in range(len(input_lst)):\n",
    "        for input_ in input_lst[i]:\n",
    "            input_mask[i,input_]  = 1.0 \n",
    "    return input_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1dbf7743",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_single2(w1, w2, W):\n",
    "    eps = 0.01\n",
    "    dw1 = W[:, w1]\n",
    "    dw2 = W[:, w2]\n",
    "   \n",
    "    correlation = np.corrcoef(dw1, dw2)[0,1]\n",
    "    if np.isnan(correlation):\n",
    "        correlation = 0.0\n",
    "    return correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b1d6020",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_ind2(topics, W):\n",
    "    scores = []\n",
    "    count = 0\n",
    "    K, V = topics.shape[0], topics.shape[1]\n",
    "    for i in range(K):\n",
    "        score = 0\n",
    "        topic = topics[i]\n",
    "        for j1 in range(len(topic) - 1):\n",
    "            for j2 in range(j1 + 1, len(topic)):\n",
    "                sc = corr_single2(topic[j1], topic[j2], W)\n",
    "                score += sc\n",
    "        scores.append(score)\n",
    "    return np.array(scores) / ((V * (V - 1) / 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "370a19a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_ind(topics, W):\n",
    "    scores = []\n",
    "    count = 0\n",
    "    K, V = topics.shape[0], topics.shape[1]\n",
    "    for i in range(K):\n",
    "        score = []\n",
    "        topic = topics[i]\n",
    "        for j1 in range(len(topic) - 1):\n",
    "            for j2 in range(j1 + 1, len(topic)):\n",
    "                sc = corr_single(topic[j1], topic[j2], W)\n",
    "                score.append(sc)\n",
    "        scores.append(np.median(score))\n",
    "    return np.array(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d432df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coherence_single(w1, w2, W):\n",
    "    if (w1 == -1)|(w2 == -1):\n",
    "        return -1\n",
    "    eps = 0.01\n",
    "    dw1 = W[:, w1] > 0\n",
    "    dw2 = W[:, w2] > 0\n",
    "    N = W.shape[0]\n",
    "\n",
    "    dw1w2 = (dw1 & dw2).float().sum() / N + eps\n",
    "    dw1 = dw1.float().sum() / N + eps\n",
    "    dw2 = dw2.float().sum() / N + eps\n",
    "\n",
    "    return dw1w2.log() - dw1.log() - dw2.log()\n",
    "\n",
    "\n",
    "# calc coherence of topics based on W\n",
    "# See appendix of https://arxiv.org/pdf/1910.05495.pdf for details\n",
    "def coherence(topics, W):\n",
    "    score = 0\n",
    "    count = 0\n",
    "    tot = 0\n",
    "    K, V = topics.shape[0], topics.shape[1]\n",
    "    for i in range(K):\n",
    "        topic = topics[i]\n",
    "        for j1 in range(len(topic) - 1):\n",
    "            for j2 in range(j1 + 1, len(topic)):\n",
    "                sc = coherence_single(topic[j1], topic[j2], W)\n",
    "                if sc == -1:\n",
    "                    tot += 1\n",
    "                else:\n",
    "                    score += sc\n",
    "    return score / ((K * V * (V - 1) / 2) - tot)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a80fcac",
   "metadata": {},
   "source": [
    "## Bassez Coherences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "748346bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kunesr/miniconda3/envs/spade_baselines/lib/python3.7/site-packages/anndata/compat/_overloaded_dict.py:106: ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual.\n",
      "  self.data[key] = value\n"
     ]
    }
   ],
   "source": [
    "X_bassez, adata2, word2id, id2word, labels, vocab, adict, weights, gene_names_dict, gs_dict, gs_names = process_Bassez_train(pseudocount = 0.0, hv = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0726cce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE = \"data/TEST_BRCA-X-TIL-X-Bassez_2021-X-cohort1_2_raw_filtered_clustered_drops_annotated_nodrops_log1p_clustered_leukocytes_scran_annotated_clustered_imputed_hvgenes_andmarker_15000_clustered_imputed_v2_210501_annotated_211208.h5ad\"\n",
    "adata_test = sc.read_h5ad(FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f07b3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "msk = np.array([var_name in adata2.var_names for var_name in adata_test.var_names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8939a172",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_test = adata_test[:,msk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "964f4b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = torch.Tensor(adata_test.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1cc2fd55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kunesr/miniconda3/envs/spade_baselines/lib/python3.7/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/home/kunesr/miniconda3/envs/spade_baselines/lib/python3.7/site-packages/numpy/core/_methods.py:181: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n",
      "/home/kunesr/miniconda3/envs/spade_baselines/lib/python3.7/site-packages/numpy/lib/function_base.py:2634: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar, dtype=dtype)\n",
      "/home/kunesr/miniconda3/envs/spade_baselines/lib/python3.7/site-packages/numpy/lib/function_base.py:2493: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "/home/kunesr/miniconda3/envs/spade_baselines/lib/python3.7/site-packages/numpy/lib/function_base.py:2493: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n"
     ]
    }
   ],
   "source": [
    "slalom_corr = []\n",
    "slalom_coh = []\n",
    "slalom_new_corr = []\n",
    "slalom_new_coh = []\n",
    "for i in range(5):\n",
    "    FA = pickle.load(open(\"baseline_models/slalom_result_subset_svg\" + str(i) + \".pickle\", \"rb\"))\n",
    "    factor_matrix = FA.getW()*FA.getZ()\n",
    "    idx_matrix = np.argsort(factor_matrix.T,axis = 1)[:,::-1][:,:50]\n",
    "    a = corr_ind(idx_matrix,test_set)\n",
    "    b = coherence_ind(idx_matrix,test_set)\n",
    "    \n",
    "    factor_matrix_new = factor_matrix[:,:10]\n",
    "    idx_matrix_new = np.argsort(factor_matrix_new.T,axis = 1)[:,::-1][:,:50]\n",
    "    a_new = corr_ind(idx_matrix_new,test_set)\n",
    "    b_new = coherence_ind(idx_matrix_new,test_set)\n",
    "    slalom_corr.append(np.median(a))\n",
    "    slalom_coh.append(np.median(b))\n",
    "    slalom_new_corr.append(np.median(a_new))\n",
    "    slalom_new_coh.append(np.median(b_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "342eb996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6230624, 0.53134656, 0.44301817, 0.5838946, 0.56410813]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spade_corr = []\n",
    "spade_coh = []\n",
    "spade_new_corr = []\n",
    "spade_new_coh = []\n",
    "lam = 0.01\n",
    "for i in range(5):\n",
    "    rand_perm = np.random.permutation(X_bassez.shape[0])\n",
    "    train_idx = np.load(\"baseline_models/idx_spectra_result_subset_svg_lam\" + str(lam) + \"run\" + str(i) + \".npy\")\n",
    "    X_train = X_bassez[train_idx,:]\n",
    "    \n",
    "    L = OrderedDict({\"global\": len(gs_names[\"global\"]) + 2})\n",
    "    for k in np.unique(labels):\n",
    "        L[k] = len(gs_names[k]) + 1\n",
    "        if k == 'nan':\n",
    "            L[k] = 0\n",
    "\n",
    "    model = SPADE(X = X_train,L = L,labels = labels[train_idx],adj_matrix = adict, weights = weights,lam = 0.1,kappa = 0.00001,rho = 0.001,delta = 0.001,beta=0.0)\n",
    "    model.load_state_dict(torch.load(\"baseline_models/spectra_result_subset_svg_lam\" + str(lam) + \"run\" + str(i)))\n",
    "    out,f = compute_thetas(model)\n",
    "    factors,names,old_factors = return_factor_matrix(model, dim = 1)\n",
    "    markers = return_markers(factors, id2word, n_top_vals= 50)\n",
    "    markers[\"cell_type\"] = f\n",
    "    markers[\"eta\"] = B_diag(model)\n",
    "    markers[\"eta_high\"] = (markers[\"eta\"] > 0.5).astype(int)\n",
    "    idx_matrix = np.argsort(factors,axis = 1)[:,::-1][:,:50]\n",
    "    a = corr_ind(idx_matrix,test_set)\n",
    "    b = coherence_ind(idx_matrix,test_set)\n",
    "    a_new = corr_ind(idx_matrix[markers[\"eta_high\"] == 0],test_set)\n",
    "    b_new = coherence_ind(idx_matrix[markers[\"eta_high\"] == 0],test_set)\n",
    "    spade_corr.append(np.median(a))\n",
    "    spade_coh.append(np.median(b))\n",
    "    spade_new_corr.append(np.median(a_new))\n",
    "    spade_new_coh.append(np.median(b_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e91f5756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter.    0]  loss:27.932743  pct:100.000000000\n",
      "[Iter.   10]  loss:1.747169  pct:-93.745084433\n",
      "[Iter.   20]  loss:1.843349  pct:5.504923987\n",
      "[Iter.   30]  loss:1.891473  pct:2.610673878\n",
      "[Iter.   40]  loss:1.908761  pct:0.914013931\n",
      "[Iter.   50]  loss:1.915305  pct:0.342846058\n",
      "getting worse break\n",
      "Reprojecting data...\n",
      "[Iter.    0]  loss:1.933964  pct:100.000000000\n",
      "[Iter.    2]  loss:1.934342  pct:0.019546003\n",
      "[Iter.    4]  loss:1.933764  pct:-0.029877169\n",
      "[Iter.    6]  loss:1.933333  pct:-0.022291281\n",
      "[Iter.    8]  loss:1.933001  pct:-0.017153808\n",
      "[Iter.   10]  loss:1.932747  pct:-0.013135830\n",
      "[Iter.   12]  loss:1.932547  pct:-0.010392855\n",
      "[Iter.   14]  loss:1.932388  pct:-0.008204115\n",
      "[Iter.   16]  loss:1.932263  pct:-0.006471296\n",
      "[Iter.   18]  loss:1.932163  pct:-0.005176138\n",
      "[Iter.   20]  loss:1.932082  pct:-0.004201588\n",
      "[Iter.   22]  loss:1.932018  pct:-0.003288606\n",
      "[Iter.   24]  loss:1.931968  pct:-0.002603822\n",
      "[Iter.   26]  loss:1.931923  pct:-0.002313883\n",
      "[Iter.   28]  loss:1.931890  pct:-0.001703057\n",
      "[Iter.   30]  loss:1.931863  pct:-0.001437751\n",
      "[Iter.   32]  loss:1.931840  pct:-0.001178602\n",
      "[Iter.   34]  loss:1.931822  pct:-0.000900932\n",
      "[Iter.   36]  loss:1.931809  pct:-0.000697303\n",
      "converged\n",
      "New best!\n",
      "Trial 0 loss: 1.931809\n",
      "Best loss: 1.931809 (trial 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kunesr/miniconda3/envs/spade_baselines/lib/python3.7/site-packages/numpy/lib/function_base.py:2634: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar, dtype=dtype)\n",
      "/home/kunesr/miniconda3/envs/spade_baselines/lib/python3.7/site-packages/numpy/lib/function_base.py:2493: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "/home/kunesr/miniconda3/envs/spade_baselines/lib/python3.7/site-packages/numpy/lib/function_base.py:2493: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n",
      "/home/kunesr/miniconda3/envs/spade_baselines/lib/python3.7/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/home/kunesr/miniconda3/envs/spade_baselines/lib/python3.7/site-packages/numpy/core/_methods.py:181: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter.    0]  loss:27.919376  pct:100.000000000\n",
      "[Iter.   10]  loss:1.746242  pct:-93.745409998\n",
      "[Iter.   20]  loss:1.843927  pct:5.593991319\n",
      "[Iter.   30]  loss:1.886413  pct:2.304121606\n",
      "[Iter.   40]  loss:1.907900  pct:1.139033711\n",
      "[Iter.   50]  loss:1.913470  pct:0.291959392\n",
      "getting worse break\n",
      "Reprojecting data...\n",
      "[Iter.    0]  loss:1.931998  pct:100.000000000\n",
      "[Iter.    2]  loss:1.932171  pct:0.008946874\n",
      "[Iter.    4]  loss:1.931447  pct:-0.037511812\n",
      "[Iter.    6]  loss:1.930904  pct:-0.028113556\n",
      "[Iter.    8]  loss:1.930489  pct:-0.021484674\n",
      "[Iter.   10]  loss:1.930166  pct:-0.016722126\n",
      "[Iter.   12]  loss:1.929912  pct:-0.013173656\n",
      "[Iter.   14]  loss:1.929705  pct:-0.010686089\n",
      "[Iter.   16]  loss:1.929539  pct:-0.008642449\n",
      "[Iter.   18]  loss:1.929403  pct:-0.007049240\n",
      "[Iter.   20]  loss:1.929288  pct:-0.005956131\n",
      "[Iter.   22]  loss:1.929192  pct:-0.004955500\n",
      "[Iter.   24]  loss:1.929112  pct:-0.004170983\n",
      "[Iter.   26]  loss:1.929043  pct:-0.003559387\n",
      "[Iter.   28]  loss:1.928984  pct:-0.003040418\n",
      "[Iter.   30]  loss:1.928935  pct:-0.002564658\n",
      "[Iter.   32]  loss:1.928890  pct:-0.002323702\n",
      "[Iter.   34]  loss:1.928853  pct:-0.001922043\n",
      "[Iter.   36]  loss:1.928818  pct:-0.001792293\n",
      "[Iter.   38]  loss:1.928791  pct:-0.001427680\n",
      "[Iter.   40]  loss:1.928765  pct:-0.001353534\n",
      "[Iter.   42]  loss:1.928741  pct:-0.001205218\n",
      "[Iter.   44]  loss:1.928722  pct:-0.001001270\n",
      "[Iter.   46]  loss:1.928704  pct:-0.000927111\n",
      "[Iter.   48]  loss:1.928689  pct:-0.000784961\n",
      "converged\n",
      "New best!\n",
      "Trial 0 loss: 1.928689\n",
      "Best loss: 1.928689 (trial 0)\n",
      "[Iter.    0]  loss:27.958929  pct:100.000000000\n",
      "[Iter.   10]  loss:1.746828  pct:-93.752163842\n",
      "[Iter.   20]  loss:1.838947  pct:5.273471968\n",
      "[Iter.   30]  loss:1.883945  pct:2.446933802\n",
      "[Iter.   40]  loss:1.907538  pct:1.252360764\n",
      "[Iter.   50]  loss:1.916254  pct:0.456892039\n",
      "getting worse break\n",
      "Reprojecting data...\n",
      "[Iter.    0]  loss:1.935124  pct:100.000000000\n",
      "[Iter.    2]  loss:1.935434  pct:0.015992118\n",
      "[Iter.    4]  loss:1.934801  pct:-0.032675123\n",
      "[Iter.    6]  loss:1.934338  pct:-0.023942890\n",
      "[Iter.    8]  loss:1.933984  pct:-0.018315829\n",
      "[Iter.   10]  loss:1.933712  pct:-0.014066076\n",
      "[Iter.   12]  loss:1.933498  pct:-0.011041142\n",
      "[Iter.   14]  loss:1.933328  pct:-0.008798129\n",
      "[Iter.   16]  loss:1.933189  pct:-0.007189574\n",
      "[Iter.   18]  loss:1.933076  pct:-0.005827303\n",
      "[Iter.   20]  loss:1.932984  pct:-0.004754616\n",
      "[Iter.   22]  loss:1.932908  pct:-0.003928450\n",
      "[Iter.   24]  loss:1.932845  pct:-0.003293367\n",
      "[Iter.   26]  loss:1.932788  pct:-0.002911087\n",
      "[Iter.   28]  loss:1.932744  pct:-0.002294398\n",
      "[Iter.   30]  loss:1.932703  pct:-0.002127918\n",
      "[Iter.   32]  loss:1.932669  pct:-0.001764050\n",
      "[Iter.   34]  loss:1.932640  pct:-0.001480348\n",
      "[Iter.   36]  loss:1.932615  pct:-0.001326165\n",
      "[Iter.   38]  loss:1.932592  pct:-0.001178144\n",
      "[Iter.   40]  loss:1.932570  pct:-0.001110305\n",
      "[Iter.   42]  loss:1.932554  pct:-0.000838907\n",
      "[Iter.   44]  loss:1.932539  pct:-0.000783397\n",
      "converged\n",
      "New best!\n",
      "Trial 0 loss: 1.932539\n",
      "Best loss: 1.932539 (trial 0)\n",
      "[Iter.    0]  loss:27.995338  pct:100.000000000\n",
      "[Iter.   10]  loss:1.749715  pct:-93.749974451\n",
      "[Iter.   20]  loss:1.830723  pct:4.629780211\n",
      "[Iter.   30]  loss:1.893735  pct:3.441938731\n",
      "[Iter.   40]  loss:1.913026  pct:1.018651685\n",
      "[Iter.   50]  loss:1.922514  pct:0.495973734\n",
      "getting worse break\n",
      "Reprojecting data...\n",
      "[Iter.    0]  loss:1.941446  pct:100.000000000\n",
      "[Iter.    2]  loss:1.941864  pct:0.021546072\n",
      "[Iter.    4]  loss:1.941282  pct:-0.029994708\n",
      "[Iter.    6]  loss:1.940825  pct:-0.023555920\n",
      "[Iter.    8]  loss:1.940457  pct:-0.018924111\n",
      "[Iter.   10]  loss:1.940157  pct:-0.015468981\n",
      "[Iter.   12]  loss:1.939911  pct:-0.012688001\n",
      "[Iter.   14]  loss:1.939704  pct:-0.010698602\n",
      "[Iter.   16]  loss:1.939532  pct:-0.008856023\n",
      "[Iter.   18]  loss:1.939385  pct:-0.007559939\n",
      "[Iter.   20]  loss:1.939260  pct:-0.006435654\n",
      "[Iter.   22]  loss:1.939151  pct:-0.005649233\n",
      "[Iter.   24]  loss:1.939058  pct:-0.004782755\n",
      "[Iter.   26]  loss:1.938976  pct:-0.004217386\n",
      "[Iter.   28]  loss:1.938906  pct:-0.003615055\n",
      "[Iter.   30]  loss:1.938845  pct:-0.003166362\n",
      "[Iter.   32]  loss:1.938792  pct:-0.002723772\n",
      "[Iter.   34]  loss:1.938741  pct:-0.002619320\n",
      "[Iter.   36]  loss:1.938703  pct:-0.001979913\n",
      "[Iter.   38]  loss:1.938662  pct:-0.002090633\n",
      "[Iter.   40]  loss:1.938630  pct:-0.001654094\n",
      "[Iter.   42]  loss:1.938600  pct:-0.001574183\n",
      "[Iter.   44]  loss:1.938574  pct:-0.001340536\n",
      "[Iter.   46]  loss:1.938549  pct:-0.001297509\n",
      "[Iter.   48]  loss:1.938528  pct:-0.001076147\n",
      "New best!\n",
      "Trial 0 loss: 1.938528\n",
      "Best loss: 1.938528 (trial 0)\n",
      "[Iter.    0]  loss:28.134794  pct:100.000000000\n",
      "[Iter.   10]  loss:1.756088  pct:-93.758304247\n",
      "[Iter.   20]  loss:1.840826  pct:4.825351203\n",
      "[Iter.   30]  loss:1.899964  pct:3.212609484\n",
      "[Iter.   40]  loss:1.923436  pct:1.235389214\n",
      "[Iter.   50]  loss:1.933037  pct:0.499171023\n",
      "getting worse break\n",
      "Reprojecting data...\n",
      "[Iter.    0]  loss:1.952075  pct:100.000000000\n",
      "[Iter.    2]  loss:1.952527  pct:0.023156983\n",
      "[Iter.    4]  loss:1.951996  pct:-0.027168966\n",
      "[Iter.    6]  loss:1.951604  pct:-0.020122713\n",
      "[Iter.    8]  loss:1.951310  pct:-0.015063003\n",
      "[Iter.   10]  loss:1.951087  pct:-0.011393647\n",
      "[Iter.   12]  loss:1.950919  pct:-0.008621055\n",
      "[Iter.   14]  loss:1.950790  pct:-0.006611471\n",
      "[Iter.   16]  loss:1.950690  pct:-0.005114757\n",
      "[Iter.   18]  loss:1.950612  pct:-0.004008904\n",
      "[Iter.   20]  loss:1.950553  pct:-0.003049578\n",
      "[Iter.   22]  loss:1.950507  pct:-0.002334618\n",
      "[Iter.   24]  loss:1.950469  pct:-0.001931300\n",
      "[Iter.   26]  loss:1.950441  pct:-0.001466838\n",
      "[Iter.   28]  loss:1.950418  pct:-0.001185712\n",
      "[Iter.   30]  loss:1.950400  pct:-0.000880126\n",
      "[Iter.   32]  loss:1.950384  pct:-0.000837350\n",
      "converged\n",
      "New best!\n",
      "Trial 0 loss: 1.950384\n",
      "Best loss: 1.950384 (trial 0)\n"
     ]
    }
   ],
   "source": [
    "schpf_corr = []\n",
    "schpf_coh = []\n",
    "for i in range(5):\n",
    "    rand_perm = np.random.permutation(X_bassez.shape[0])\n",
    "    train_idx = rand_perm[:10000]\n",
    "    X_train = X_bassez[train_idx,:]\n",
    "    model_kwargs = dict(a=1.25, c=1.25)\n",
    "    model = run_trials(scipy.sparse.coo_matrix(X_train), vcells=None, nfactors=40, \n",
    "                            ntrials=1, min_iter=20,\n",
    "                            max_iter=1000, check_freq=10,\n",
    "                            epsilon=0.001,\n",
    "                            better_than_n_ago=5, dtype=np.float32,\n",
    "                            verbose=True, model_kwargs=model_kwargs,\n",
    "                            return_all=False, reproject=True,\n",
    "                            batchsize=0,\n",
    "                            beta_theta_simultaneous=True,\n",
    "                            loss_smoothing=1\n",
    "                            )\n",
    "    factors = model.gene_score().T\n",
    "    idx_matrix = np.argsort(factors,axis = 1)[:,::-1][:,:50]\n",
    "    a = corr_ind(idx_matrix,test_set)\n",
    "    b = coherence_ind(idx_matrix,test_set)\n",
    "    schpf_corr.append(np.median(a))\n",
    "    schpf_coh.append(np.median(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "93ad0ff3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kunesr/miniconda3/envs/spade_baselines/lib/python3.7/site-packages/sklearn/decomposition/_nmf.py:1641: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kunesr/miniconda3/envs/spade_baselines/lib/python3.7/site-packages/sklearn/decomposition/_nmf.py:1641: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kunesr/miniconda3/envs/spade_baselines/lib/python3.7/site-packages/sklearn/decomposition/_nmf.py:1641: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kunesr/miniconda3/envs/spade_baselines/lib/python3.7/site-packages/numpy/lib/function_base.py:2634: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar, dtype=dtype)\n",
      "/home/kunesr/miniconda3/envs/spade_baselines/lib/python3.7/site-packages/numpy/lib/function_base.py:2493: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "/home/kunesr/miniconda3/envs/spade_baselines/lib/python3.7/site-packages/numpy/lib/function_base.py:2493: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kunesr/miniconda3/envs/spade_baselines/lib/python3.7/site-packages/sklearn/decomposition/_nmf.py:1641: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kunesr/miniconda3/envs/spade_baselines/lib/python3.7/site-packages/sklearn/decomposition/_nmf.py:1641: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n"
     ]
    }
   ],
   "source": [
    "nmf_corr = []\n",
    "nmf_coh = []\n",
    "for i in range(5):\n",
    "    print(i)\n",
    "    rand_perm = np.random.permutation(X_bassez.shape[0])\n",
    "    train_idx = rand_perm[:10000]\n",
    "    X_train = X_bassez[train_idx,:]\n",
    "    model = NMF(n_components = 40)\n",
    "    model.fit(X_train)\n",
    "    print(\"done training\")\n",
    "    factors = model.components_\n",
    "    idx_matrix = np.argsort(factors,axis = 1)[:,::-1][:,:50]\n",
    "    a = corr_ind(idx_matrix,test_set)\n",
    "    b = coherence_ind(idx_matrix,test_set)\n",
    "    nmf_corr.append(np.median(a))\n",
    "    nmf_coh.append(np.median(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c44fa227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.16084677, 0.15881297, 0.14519204, 0.1677877, 0.14035916]\n"
     ]
    }
   ],
   "source": [
    "print(nmf_coh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "14a0f73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"spectra_lam0.01\"]*5 + [\"schpf\"]*5 + [\"slalom\"]*5 + [\"nmf\"]*5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f7d1a0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "coherences = spade_coh +schpf_coh + slalom_coh + nmf_coh "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7a27a939",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\")\n",
    "df = pd.DataFrame()\n",
    "#df[\"corr\"] = conditional_correlation\n",
    "df[\"coherence\"] = coherences\n",
    "df[\"model\"] = models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0cd53722",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_style(\"white\")\n",
    "sns.boxplot(data =df, x = \"model\", y = \"coherence\", fliersize=0)\n",
    "sns.stripplot(data = df, x = \"model\", y = \"coherence\", color = \"black\")\n",
    "plt.ylim(0,0.8)\n",
    "plt.savefig(\"figures/coh_subset.svg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
